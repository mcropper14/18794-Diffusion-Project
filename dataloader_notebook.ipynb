{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7Pa4ANJkcqC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test folders should list\n",
        "!ls /content/drive/MyDrive/18794-Diffusion-Project/tiny-imagenet-200/train\n",
        "#/content/drive/MyDrive/18794-Diffusion-Project/tiny-imagenet-200/train"
      ],
      "metadata": {
        "id": "cncLx-dqkhgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "import os\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/18794-Diffusion-Project/tiny-imagenet-200\"\n",
        "print(\"Base path exists:\", os.path.exists(base_path))\n",
        "print(\"Train path exists:\", os.path.exists(os.path.join(base_path, \"train\")))\n",
        "!ls -d /content/drive/MyDrive/18794-Diffusion-Project/tiny-imagenet-200/train/* | head"
      ],
      "metadata": {
        "id": "FJixoGX0klZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loader"
      ],
      "metadata": {
        "id": "6Y86NLTlkq_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/18794-Diffusion-Project/tiny-imagenet-200\"\n",
        "TRAIN_ROOT = os.path.join(DATASET_DIR, \"train\")\n",
        "\n",
        "SELECTED_CLASSES = [\n",
        "    'n02123045',  # cat\n",
        "    'n02504458',  # elephant\n",
        "    'n01641577',  # frog\n",
        "    'n01443537', #fish\n",
        "    'n01629819', #lizard\n",
        "    'n01742172', #snake\n",
        "    'n01855672', #goose\n",
        "    'n01910747', #jellyfish\n",
        "    'n01944390', #snail\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "# Native tiny-ImageNet size\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "EXTS = [\"jpg\", \"jpeg\", \"png\", \"bmp\", \"tif\", \"tiff\", \"webp\", \"ppm\"]\n",
        "\n",
        "def collect_paths_for_class(train_root, wnid):\n",
        "    \"\"\"\n",
        "    Return a list of image paths for a given wnid.\n",
        "    Handles both: train/<wnid>/*.JPEG  and train/<wnid>/images/*.JPEG\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "    for ext in EXTS + [e.upper() for e in EXTS]:\n",
        "        paths.extend(glob.glob(os.path.join(train_root, wnid, f\"*.{ext}\")))\n",
        "\n",
        "    for ext in EXTS + [e.upper() for e in EXTS]:\n",
        "        paths.extend(glob.glob(os.path.join(train_root, wnid, \"images\", f\"*.{ext}\")))\n",
        "    return sorted(paths)\n",
        "\n",
        "class TinyImageNetSubset(Dataset):\n",
        "    def __init__(self, train_root, selected_classes, transform=None):\n",
        "        if not os.path.isdir(train_root):\n",
        "            raise FileNotFoundError(f\"train_root not found: {train_root}\")\n",
        "\n",
        "        self.transform = transform\n",
        "        self.selected = [wnid for wnid in selected_classes if os.path.isdir(os.path.join(train_root, wnid))]\n",
        "        self.missing = [wnid for wnid in selected_classes if wnid not in self.selected]\n",
        "\n",
        "        # wnid to new id in [0..K-1] (order of SELECTED_CLASSES)\n",
        "        self.class_to_new = {wnid: i for i, wnid in enumerate(selected_classes) if wnid in self.selected}\n",
        "        self.new_to_class = {v: k for k, v in self.class_to_new.items()}\n",
        "\n",
        "        # Collect samples only from the selected classes\n",
        "        self.samples = []\n",
        "        for wnid in self.selected:\n",
        "            files = collect_paths_for_class(train_root, wnid)\n",
        "            if not files:\n",
        "                print(f\"[warn] No images found for {wnid} under {train_root}/{wnid} or {train_root}/{wnid}/images\")\n",
        "            for p in files:\n",
        "                self.samples.append((p, self.class_to_new[wnid]))\n",
        "\n",
        "        if len(self.samples) == 0:\n",
        "            raise FileNotFoundError(\n",
        "                \"No images found for the selected classes. \"\n",
        "                \"Check folder names, structure, or permissions.\"\n",
        "            )\n",
        "\n",
        "        #debug\n",
        "        counts = Counter([t for _, t in self.samples])\n",
        "        print(\"\\n--- Subset summary ---\")\n",
        "        if self.missing:\n",
        "            print(\"Missing classes:\", self.missing)\n",
        "        else:\n",
        "            print(\"Missing classes: (none)\")\n",
        "        for new_id in sorted(counts):\n",
        "            print(f\"{new_id:2d} -> {self.new_to_class[new_id]}: {counts[new_id]} images\")\n",
        "        print(f\"TOTAL images in subset: {len(self.samples)}\\n\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, target = self.samples[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, target\n",
        "\n",
        "\n",
        "subset = TinyImageNetSubset(TRAIN_ROOT, SELECTED_CLASSES, transform=train_transform)\n",
        "loader = DataLoader(subset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "#debug\n",
        "imgs, labels = next(iter(loader))\n",
        "print(\"Batch:\", imgs.shape, labels.shape)\n"
      ],
      "metadata": {
        "id": "ECyj4tsQkohI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show Images loaded"
      ],
      "metadata": {
        "id": "MQBQJv_Lkvjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "grid = torchvision.utils.make_grid(imgs[:16], nrow=8)\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(grid.permute(1,2,0).cpu().numpy())\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eCRpKcnvkyiY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}